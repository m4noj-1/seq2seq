# ğŸ”¡ Seq2Seq â€” Hindi Transliteration Model

A deep learning project implementing a **Sequence-to-Sequence (Seq2Seq)** model with **attention mechanism** for transliterating **romanized Hindi text to Devanagari script**.  
Built using **PyTorch** and trained on the **Aksharantar dataset**.

---

## ğŸ¯ Overview

This project tackles the problem of **character-level transliteration** from romanized Hindi (Latin script) to Devanagari script using a neural sequence-to-sequence model.  
Unlike traditional rule-based systems, this model **learns the mapping directly from data** using:

- ğŸ§© **Encoderâ€“Decoder Architecture** with LSTM cells  
- ğŸ¯ **Bahdanau Attention Mechanism** for better alignment  
- ğŸ”„ **Bidirectional Encoder** for capturing context from both directions  
- ğŸ§® **Beam Search Decoding** for improved inference quality  

---

## âœ¨ Features

- ğŸ§  3-Layer Deep LSTM Encoder and Decoder  
- ğŸ¯ Bahdanau Attention Mechanism for better character alignment  
- ğŸ”„ Bidirectional Encoder for enhanced context understanding  

---

## ğŸš€ Quick Start (Google Colab Recommended)

### Step 1: Open Google Colab
- Go to [colab.research.google.com](https://colab.research.google.com)  
- Create a **new notebook**

### Step 2: Enable GPU
- Click **Runtime â†’ Change runtime type**  
- Select **GPU** under *Hardware accelerator*  
- Click **Save**

### Step 3: Download Dataset Files
From this repository, download:
- `hin_train.csv`  
- `hin_valid.csv`  
- `hin_test.csv` *(optional)*  

### Step 4: Upload Files to Colab
- Click the ğŸ“ **Files** icon in the left sidebar  
- Click ğŸ“¤ **Upload**  
- Upload all three CSV files

### Step 5: Copy the Code
- Open `transliteration_model.py` from this repo  
- Copy the entire code  
- Paste it into a new code cell in Colab

### Step 6: Run the Code
Thatâ€™s it! ğŸ‰  
No installation, no setup â€” just upload files and run.

---

## ğŸ“Š Dataset

This project uses the **Aksharantar dataset** (Hindi transliteration subset) from [AI4Bharat](https://ai4bharat.org/).

| File | Samples | Description |
|------|----------|-------------|
| `hin_train.csv` | ~90,000 | Training data |
| `hin_valid.csv` | ~10,000 | Validation data |
| `hin_test.csv`  | ~10,000 | Test data |

**Data Format:**  
ghar,à¤˜à¤°
dost,à¤¦à¥‹à¤¸à¥à¤¤
namaste,à¤¨à¤®à¤¸à¥à¤¤à¥‡
kitaab,à¤•à¤¿à¤¤à¤¾à¤¬



> âš ï¸ Ensure all three CSV files are in the **same directory** as your code/notebook.

---

## ğŸ“ˆ Model Performance

**Training Results**
- ğŸ§© Word Accuracy: **55%** âœ¨  
- ğŸ”¤ Character Accuracy: **70%+** ğŸ”¥  
- ğŸ“‰ Training Loss: ~0.8 â€“ 1.2  
- ğŸ“‰ Validation Loss: ~1.0 â€“ 1.5  
- ğŸ§  Test Loss: ~1.2 â€“ 1.8  
- âš¡ Training Time: ~60 â€“ 70 minutes on Colab T4 GPU (40 epochs)

**Performance Highlights**
- ğŸ’¬ 55% **Word-Level Accuracy** â€” more than half the words are perfectly transliterated!  
- ğŸ”  70%+ **Character-Level Accuracy** â€” most characters are correct even when the full word isnâ€™t.  

This is **strong performance** for a character-level Seq2Seq task with a complex script like Devanagari.

---

## ğŸ§ª Sample Predictions

<img width="589" height="313" alt="Seq2Seq transliteration sample" src="https://github.com/user-attachments/assets/b3859fc9-7e3f-4f47-8221-0a2b27ae4dc2" />

---

ğŸ’¡ *Optimized for Colab â€” run instantly, no setup required!*

Each CSV contains pairs of romanized Hindi and Devanagari text:  

